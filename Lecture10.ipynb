{"cells":[{"cell_type":"markdown","metadata":{"collapsed":false,"id":"B2E13C03C0E748919DA40A0B58CB4468","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"# Lecture 10: Model evaluation & comparison (1)\n\n## Instructor： 胡传鹏（博士）[Dr. Hu Chuan-Peng]\n\n### 南京师范大学心理学院[School of Psychology, Nanjing Normal University]"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"543A644E8F7944B9BAFCD281B8818FDC","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"##  Recap: Linear Model and model diagnositcs\n\n* Workflow\n* MCMC diagnostics"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"4F862DA11B554DB289B4E89D1E2922C4","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"我们在上节课中采用一个简化的workflow，具体包括如下几个步骤：\n"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"D1C645DC1627451E809A160B16451896","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"\n![Image Name](https://cdn.kesci.com/upload/image/rkz1ehen1l.png?imageView2/0/w/960/h/960)\n\n\n"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"C0D7787982734EC384AD5C3B652E8A0D","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"现在，我们通过上节课的例子来简单回顾一下workflow"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"A2C3D390E20D44858DF0526DD185459C","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"在本例中，涉及：研究问题、数据收集、选择模型、选择先验、模型拟合、采样过程评估/模型诊断"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"6FF8EC3420AA40608BCFA62EF53D10CB","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (1) 提出研究问题\n\n还有研究发现个体创新行为可能与自尊水平有关。\nSES_t: 自尊水平；\nEIB_t: 创新行为"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"67488C0B681C40AF8373C9C410AEF7F8","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (2) 数据收集"},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":false,"id":"8DFB687F35914AFB8C05853D55E5D139","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"WARNING (theano.link.c.cmodule): install mkl with `conda install mkl-service`: No module named 'mkl'\n"},{"output_type":"execute_result","data":{"text/plain":"Text(0, 0.5, 'EIB_t')"},"metadata":{},"execution_count":1},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/8DFB687F35914AFB8C05853D55E5D139/rkyxj65t83.png\">"},"metadata":{"needs_background":"light"}}],"source":"#加载需要使用的库\n%matplotlib inline\nimport numpy as np \nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport arviz as az\nimport pymc3 as pm\n# mpl_toolkits.mplot3d是用于三维画图的，Axes3D用于画三维图\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#数据预处理与可视化\nnp.random.seed(123)  # 随机数种子，确保随后生成的随机数相同\ndata = pd.read_csv(\"/home/mw/input/data9464/clean.csv\") # 读取数据，该数据需要提前挂载\ndata['SES_t'] = (data['SES_t'] - data['SES_t'].mean()) / data['SES_t'].std()#将变量进行标准化\n\ndata['EIB_t'] = (data['EIB_t'] - data['EIB_t'].mean()) / data['EIB_t'].std()#将变量进行标准化\n\nplt.scatter(data['SES_t'],data['EIB_t'])\nplt.xlabel('SES_t')\nplt.ylabel('EIB_t')"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"59B8B93E4D324F5DAB64DA0CEB5CCA31","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (3) 模型设定\n\n尝试构建一个简单的线性模型\n\n线性模型可以用概率的形式进行表达\n\n\n$\\alpha \\sim Normal(0,1)$      ->      a $\\sim$ Normal(mu,sigma)\n\n$\\beta  \\sim Normal(0,1)$      ->      b $\\sim$ Normal(mu,sigma)\n\n$\\sigma \\sim HalfNormal(1)$      ->      sigma $\\sim$ HalfNormal(1)\n\n$\\mu_i  = \\alpha + \\beta *x$      ->      mu = alpha + beta*x \n\n$y \\sim Normal(\\mu_i,sigma)$      ->      y $\\sim$ Normal(mu,sigma)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"C24612EBE8DE46538C3C68A040CD7B57","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (4) 选择先验"},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":false,"id":"8E89C676474E4E2AA6E63B19D7FA8B90","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"# 在pymc3中，pm.Model()定义了一个新的模型对象，这个对象是模型中随机变量的容器\n# 在python中，容器是一种数据结构，是用来管理特殊数据的对象\n# with语句定义了一个上下文管理器，以 linear_model 作为上下文，在这个上下文中定义的变量都被添加到这个模型\nwith pm.Model() as linear_model:\n    # 先验分布: alpha, beta, sigma这三个参数是随机变量\n    alpha = pm.Normal('alpha',mu=0,sd=1)\n    beta = pm.Normal('beta',mu=0,sd=1, shape=1)  \n    sigma = pm.HalfNormal('sigma',sd=1)\n    \n    # 先验预测检查\n    prior_checks = pm.sample_prior_predictive(samples=50)"},{"cell_type":"code","execution_count":3,"metadata":{"collapsed":false,"id":"47053D46ABF54C6FB352FD0DF7715D11","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/47053D46ABF54C6FB352FD0DF7715D11/rkyxjpx9zt.png\">"},"metadata":{"needs_background":"light"}}],"source":"fig, ax = plt.subplots()\nx1 = np.linspace(-3, 3, 50) # 生成从-2，2之间的50个假数据\n\nfor a, b in zip(prior_checks[\"alpha\"], prior_checks[\"beta\"]):\n    y = a + b * x1          # 基于假数据生成预测值\n    ax.plot(x1,y)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9DA3B2B9238B492D85420F56F0A3C620","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (5) 拟合数据"},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"id":"8E7C0A6A910546508B4063B77A8C8B8B","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[],"source":"linear_model = pm.Model()\nwith linear_model :\n    # 在pymc3中，pm.Model()定义了一个新的模型对象，这个对象是模型中随机变量的容器\n    # 在python中，容器是一种数据结构，是用来管理特殊数据的对象\n    # with语句定义了一个上下文管理器，以 linear_model 作为上下文，在这个上下文中定义的变量都被添加到这个模型\n    alpha = pm.Normal('alpha', mu=0, sd=1)\n    beta = pm.Normal('beta', mu=0, sd=1, shape=1)\n    sigma = pm.HalfNormal('sigma', sd=1)\n    # x为自变量，是之前已经载入的数据\n    x = pm.Data(\"x\", data['SES_t'])\n    # 线性模型：mu是确定性随机变量，这个变量的值完全由右端值确定\n    mu = pm.Deterministic(\"mu\", alpha + beta*x) \n    # Y的观测值，这是一个特殊的观测随机变量，表示模型数据的可能性。也可以表示模型的似然，通过 observed 参数来告诉这个变量其值是已经被观测到了的，不会被拟合算法改变\n    y_obs = pm.Normal('y_obs', mu=mu, sd=sigma, observed=data['EIB_t'])"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9DE229BD2025423B85C917275D6C3E63","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (6) 采样过程诊断\n\n如果使用MCMC对后验进行近似，则需要首先对MCMC过程进行评估。\n\n* 是否收敛；\n* 是否接近真实的后验。\n\n对采样过程的评估我们会采用目视检查或rhat这个指标"},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":false,"id":"7776FCCFB2C5441893BE0B223D3C3B89","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Auto-assigning NUTS sampler...\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (2 chains in 2 jobs)\nNUTS: [sigma, beta, alpha]\n"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"stream","name":"stderr","text":"Sampling 2 chains for 1_000 tune and 2_000 draw iterations (2_000 + 4_000 draws total) took 6 seconds.\n"}],"source":"with linear_model :\n    # 使用mcmc方法进行采样，draws为采样次数，tune为调整采样策略的次数，这些次数将在采样结束后被丢弃，\n    # target_accept为接受率， return_inferencedata=True为该函数返回的对象是arviz.InnferenceData对象\n    # chains为我们采样的链数，cores为我们的调用的cpu数，多个链可以在多个cpu中并行计算，我们在和鲸中调用的cpu数为2\n    trace = pm.sample(draws=2000, tune=1000, target_accept=0.9, chains=2, cores= 2, return_inferencedata=True)"},{"cell_type":"code","execution_count":6,"metadata":{"collapsed":false,"id":"215CDFEF736E45A68BCFFCB03E74A7B6","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"array([[<AxesSubplot:title={'center':'alpha'}>,\n        <AxesSubplot:title={'center':'alpha'}>],\n       [<AxesSubplot:title={'center':'beta'}>,\n        <AxesSubplot:title={'center':'beta'}>],\n       [<AxesSubplot:title={'center':'sigma'}>,\n        <AxesSubplot:title={'center':'sigma'}>]], dtype=object)"},"metadata":{},"execution_count":6},{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 6 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/215CDFEF736E45A68BCFFCB03E74A7B6/rkyxldpabt.png\">"},"metadata":{"needs_background":"light"}}],"source":"az.plot_trace(trace,var_names=['alpha','beta','sigma'])"},{"cell_type":"code","execution_count":7,"metadata":{"collapsed":false,"id":"9C6692072E1C44D78988AF65F5E5A4ED","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"         mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat\nalpha          0.0      0.0    5018.0    2745.0    1.0\nbeta[0]        0.0      0.0    4503.0    3309.0    1.0\nsigma          0.0      0.0    4367.0    3085.0    1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>alpha</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5018.0</td>\n      <td>2745.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>beta[0]</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4503.0</td>\n      <td>3309.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>sigma</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4367.0</td>\n      <td>3085.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":7}],"source":"az.summary(trace, var_names=['alpha','beta','sigma'], kind=\"diagnostics\")"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"0C5F6A4325D84CF58C46E8E009EB0CA3","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### (7) 模型诊断\n\n在MCMC有效的前提下，需要继续检验模型是否能够较好地拟合数据。\n\n我们会使用后验预测分布通过我们得到的参数生成一批模拟数据，并将其与真实数据进行对比。"},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":false,"id":"08DBC6B10B134772855BE0F0CF010E27","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"update_display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [4000/4000 00:05&lt;00:00]\n    </div>\n    "},"metadata":{}},{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/arviz/data/io_pymc3.py:100: FutureWarning: Using `from_pymc3` without the model will be deprecated in a future release. Not using the model will return less accurate and less useful results. Make sure you use the model argument or call from_pymc3 within a model context.\n  FutureWarning,\n"}],"source":"# 后验预测分布的计算仍在容器中进行\nwith linear_model:\n    # pm.sample_posterior_predictive()利用trace.posterior的后验分布计算后验预测分布\n    ppc_y = pm.sample_posterior_predictive(trace.posterior) \n#将ppc_y转化为InferenceData对象合并到trace中\naz.concat(trace, az.from_pymc3(posterior_predictive=ppc_y), inplace=True)"},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false,"id":"B3201FD32B234C05BD6942227CDE422E","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:xlabel='y_obs'>"},"metadata":{},"execution_count":9},{"output_type":"stream","name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/IPython/core/events.py:89: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n  func(*args, **kwargs)\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","text/html":"<img src=\"https://cdn.kesci.com/upload/rt/B3201FD32B234C05BD6942227CDE422E/rkyxmeilvx.png\">"},"metadata":{"needs_background":"light"}}],"source":"# 绘制后验预测分布\naz.plot_ppc(trace)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"57BE24124330453D9B958A8CA14CDB48","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"## Part 2: 模型评估/比较与选择(Model evaluation/comparison & selection)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"9BF407CFF89149FABD2C42487A5E9ADA","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"我们在上节课中提到的workflow具体包括如下几个步骤：\n\n研究问题、选择模型、选择先验、模型拟合、采样过程评估、模型评估、模型比较、统计推断、结果报告。\n\n\n![Image Name](https://cdn.kesci.com/upload/image/rkz1dqyo2e.png?imageView2/0/w/960/h/960)"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"D69BCF4358754FB286D2FEA8C4A6F149","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"在贝叶斯的workflow中，MCMC评估是对MCMC进行检验，在Gelman et al (2020)中也被称为计算过程的验证(validate computation)，其核心在于确定MCMC算法采样得到的样本是否足以提供目标分布的精确近似。\n\n模型评估则是指对模型是否有效/可信进行评估，既可以是对单个模型，也可以是对多个模型进行。\n\n模型评估的核心在于模型捕捉到了数据中的关键模式，既非太简单而错过数据中有价值的信息(**欠拟合, underfitting**)，也不会太复杂从而将数据中的噪音加入到模型中(**过拟合, overfitting**)。"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"B549FBCA33B34ECAB8A4403241264779","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"\n![Image Name](https://img-blog.csdnimg.cn/20210303141100499.png#pic_center)\n\n资料来源：https://blog.csdn.net/weixin_43378396/article/details/90707493"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"7C33039E93CF4261A664628B5D5B9D68","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### 欠拟合(underfitting)\n\n* 欠拟合的模型在当前样本的数据拟合效果不好，且其泛化能力(模型在当前样本外新的数据上的预测的准确度)也同样不佳。\n\n### 过拟合(overfitting)\n\n* 模型在当前样本的数据上的拟合程度极好，但是泛化能力也较差。\n\n* 模型把训练样本学习地“太好了”，把样本自身地一些噪音也当作了所有潜在样本都会具有的一些性质，这样就会导致其泛化性能下降。"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"FD588A1708B8432D857C2BF7F362D2FC","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"\n### 为什么会发生欠拟合\n\n- 数据特征较少\n\n数据特征指的是数据的属性，比如第一部分中展示的数据的各个变量就是数据的特征。在所有变量都能独立地对目标变量做出解释的前提下，数据特征越多，数据拟合程度越好。\n\n- 模型复杂度过低\n\n模型的复杂度代表模型能够描述的所有函数，比如线性回归最多能表示所有的线性函数。\n\n模型的复杂度和模型的参数数量有关，一般来说，模型参数越多，复杂度越高，模型参数越少，复杂度越低。\n\n### 为什么会发生过拟合\n\n- 当前样本的噪音过大，模型将噪音当作数据本身的特征\n\n当数据的有些特征与目标变量无关，这些特征就是噪音，但它也可能被误当作数据特征，这就会造成模型过拟合\n\n- 样本选取有误，样本不能代表整体\n\n- 模型参数太多，模型复杂度太高\n"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"442CF350FF804ACE8048EEAA95234CF8","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"\n![Image Name](https://vitalflux.com/wp-content/uploads/2020/12/overfitting-and-underfitting-wrt-model-error-vs-complexity-768x443.png)\n\n资料来源：https://vitalflux.com/overfitting-underfitting-concepts-interview-questions/"},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"6183013BDE0546EBA62A7B6501434279","jupyter":{},"notebookId":"637b54717b4e5f9b3d48837e","scrolled":false,"slideshow":{"slide_type":"slide"},"tags":[],"trusted":true},"source":"### 如何避免欠拟合\n\n- 增加数据的特征\n\n- 增加模型复杂度\n\n### 如何避免过拟合\n\n- 选择更具代表性的数据\n\n- 降低模型复杂度\n\n\n**问题的本质在于：模型与数据真实的生成模型匹配**"},{"cell_type":"code","source":"","metadata":{"id":"0D3923A1486941098AC9741BFEE5BFDB","notebookId":"637b54717b4e5f9b3d48837e","jupyter":{},"collapsed":false,"scrolled":false,"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"outputs":[],"execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}